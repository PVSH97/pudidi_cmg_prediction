"""
Live API Handler - Fetches real-time data from SIP API and makes predictions
This is the ORIGINAL working system that fetches CMG data and trains ML models
"""

import json
import requests
from datetime import datetime, timedelta
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import pytz
import time
import os

# Configuration
SIP_API_KEY = os.environ.get('SIP_API_KEY', '1a81177c8ff4f69e7dd5bb8c61bc08b4')
SIP_BASE_URL = 'https://sipub.api.coordinador.cl:443'
CHILOE_NODE = 'CHILOE________220'

def fetch_cmg_data_with_retry(date_str, max_retries=3):
    """
    Fetch CMG data from SIP API with retry logic for 429/500 errors
    """
    url = f"{SIP_BASE_URL}/costo-marginal-online/v4/findByDate"
    all_data = []
    page = 1
    limit = 1000
    
    while True:
        params = {
            'startDate': date_str,
            'endDate': date_str,
            'page': page,
            'limit': limit,
            'user_key': SIP_API_KEY
        }
        
        retries = 0
        while retries < max_retries:
            try:
                response = requests.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    records = data.get('data', [])
                    
                    # Filter for ChiloÃ© node
                    for record in records:
                        if record.get('barra_transf') == CHILOE_NODE:
                            all_data.append(record)
                    
                    # Check if this is the last page
                    if len(records) < limit:
                        return all_data
                    
                    page += 1
                    break  # Success, move to next page
                    
                elif response.status_code in [429, 500, 502, 503]:
                    # Rate limit or server error - wait and retry
                    wait_time = 2 ** retries
                    time.sleep(wait_time)
                    retries += 1
                else:
                    # Other error
                    return all_data
                    
            except Exception as e:
                retries += 1
                if retries >= max_retries:
                    return all_data
                time.sleep(2 ** retries)
        
        # Safety limit to prevent infinite loops
        if page > 50:  # Reduced for faster response
            break
    
    return all_data

def prepare_ml_features(cmg_data):
    """
    Prepare features for ML model training
    Using safe lag features: 24h, 48h, 168h (weekly)
    """
    features = []
    targets = []
    
    # Sort data by time
    sorted_data = sorted(cmg_data, key=lambda x: x['fecha_hora'])
    
    # Extract values
    values = [float(d['cmg']) for d in sorted_data]
    hours = [int(d['fecha_hora'][11:13]) for d in sorted_data]
    
    if len(values) < 24:
        # Not enough data for lag features
        return np.array([[h] for h in hours]), np.array(values)
    
    # Create features with lag
    for i in range(24, len(values)):
        feature_row = [
            hours[i],  # Hour of day
            values[i-1] if i > 0 else values[i],  # Previous value
            np.mean(values[max(0,i-24):i]),  # 24h average
            np.std(values[max(0,i-24):i]),   # 24h std
            np.max(values[max(0,i-24):i]),   # 24h max
            np.min(values[max(0,i-24):i]),   # 24h min
        ]
        features.append(feature_row)
        targets.append(values[i])
    
    return np.array(features), np.array(targets)

def train_ensemble_model(features, targets):
    """
    Train ensemble of ML models for robust predictions
    """
    models = {
        'rf': RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42),
        'lr': LinearRegression()
    }
    
    trained_models = {}
    for name, model in models.items():
        try:
            model.fit(features, targets)
            trained_models[name] = model
        except:
            pass
    
    return trained_models

def make_predictions(models, last_values, hours_ahead=48):
    """
    Make predictions for the next 48 hours
    """
    santiago_tz = pytz.timezone('America/Santiago')
    current_time = datetime.now(santiago_tz)
    
    predictions = []
    
    for i in range(hours_ahead):
        future_time = current_time + timedelta(hours=i+1)
        hour = future_time.hour
        
        # Prepare features for prediction
        if last_values:
            feature = [
                hour,
                last_values[-1] if last_values else 60,
                np.mean(last_values[-24:]) if len(last_values) >= 24 else 60,
                np.std(last_values[-24:]) if len(last_values) >= 24 else 10,
                np.max(last_values[-24:]) if len(last_values) >= 24 else 80,
                np.min(last_values[-24:]) if len(last_values) >= 24 else 40,
            ]
        else:
            # Default features if no historical data
            feature = [hour, 60, 60, 10, 80, 40]
        
        # Get predictions from all models
        preds = []
        for model in models.values():
            try:
                pred = model.predict([feature])[0]
                preds.append(pred)
            except:
                preds.append(60)  # Default prediction
        
        # Ensemble average
        final_pred = np.mean(preds) if preds else 60
        
        predictions.append({
            'datetime': future_time.strftime('%Y-%m-%d %H:%M:%S'),
            'hour': hour,
            'cmg_predicted': round(final_pred, 2),
            'confidence_lower': round(final_pred * 0.85, 2),
            'confidence_upper': round(final_pred * 1.15, 2),
            'is_prediction': True
        })
        
        # Add predicted value to history for next prediction
        last_values.append(final_pred)
    
    return predictions

def handler(request):
    """
    Vercel serverless function handler - LIVE API VERSION
    Fetches real-time data from SIP API and trains ML models
    """
    
    # Handle CORS
    if request.method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type'
            },
            'body': ''
        }
    
    try:
        santiago_tz = pytz.timezone('America/Santiago')
        today = datetime.now(santiago_tz).strftime('%Y-%m-%d')
        yesterday = (datetime.now(santiago_tz) - timedelta(days=1)).strftime('%Y-%m-%d')
        
        # Fetch CMG data from SIP API
        print(f"Fetching CMG data for {yesterday} and {today}...")
        
        cmg_data = []
        cmg_data.extend(fetch_cmg_data_with_retry(yesterday))
        cmg_data.extend(fetch_cmg_data_with_retry(today))
        
        # Sort by datetime
        cmg_data.sort(key=lambda x: x['fecha_hora'])
        
        # Calculate statistics
        if cmg_data:
            values = [float(d['cmg']) for d in cmg_data]
            recent_values = values[-24:] if len(values) >= 24 else values
            
            stats = {
                'data_points': len(cmg_data),
                'avg_24h': round(np.mean(recent_values), 2),
                'max_48h': round(max(values), 2) if values else 0,
                'min_48h': round(min(values), 2) if values else 0,
                'last_actual': round(values[-1], 2) if values else 0,
                'hours_covered': len(set(d['fecha_hora'][11:13] for d in cmg_data[-24:])),
                'method': 'Live ML Ensemble'
            }
            
            # Prepare features and train models
            features, targets = prepare_ml_features(cmg_data)
            
            if len(features) > 0:
                # Train ensemble models
                models = train_ensemble_model(features, targets)
                
                # Make predictions
                predictions = make_predictions(models, values, hours_ahead=48)
            else:
                # Not enough data for ML, use simple average
                avg_value = np.mean(values) if values else 60
                predictions = []
                for i in range(48):
                    future_time = datetime.now(santiago_tz) + timedelta(hours=i+1)
                    predictions.append({
                        'datetime': future_time.strftime('%Y-%m-%d %H:%M:%S'),
                        'hour': future_time.hour,
                        'cmg_predicted': round(avg_value, 2),
                        'confidence_lower': round(avg_value * 0.85, 2),
                        'confidence_upper': round(avg_value * 1.15, 2),
                        'is_prediction': True
                    })
            
            # Add historical data
            historical = []
            for d in cmg_data[-24:]:
                historical.append({
                    'datetime': d['fecha_hora'],
                    'hour': int(d['fecha_hora'][11:13]),
                    'cmg_actual': round(float(d['cmg']), 2),
                    'is_historical': True
                })
            
            all_predictions = historical + predictions
            
        else:
            # No data fetched - return error
            stats = {
                'data_points': 0,
                'avg_24h': 0,
                'max_48h': 0,
                'min_48h': 0,
                'last_actual': 0,
                'hours_covered': 0,
                'method': 'No data available'
            }
            all_predictions = []
        
        result = {
            'success': True if cmg_data else False,
            'location': 'ChiloÃ© 220kV',
            'node': CHILOE_NODE,
            'data_source': 'SIP API Live',
            'api_url': SIP_BASE_URL,
            'fetch_date': today,
            'stats': stats,
            'predictions': all_predictions[:72]  # Limit to 72 entries
        }
        
        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type',
                'Cache-Control': 'max-age=300'  # Cache for 5 minutes
            },
            'body': json.dumps(result)
        }
        
    except Exception as e:
        error_result = {
            'success': False,
            'error': str(e),
            'message': 'Failed to fetch data or generate predictions',
            'data_source': 'SIP API Live',
            'api_url': SIP_BASE_URL
        }
        
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps(error_result)
        }